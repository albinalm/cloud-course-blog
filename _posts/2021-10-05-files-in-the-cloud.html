---
layout: post
title: Cloud based file storage
date: 2021-09-30 17:00 -0400
subtitle: Storing files in blobs? Uh...
categories: [Assignments, Azure, Storage]
background: '/img/posts/files_cloud/banner.jpg'
---
<head>
    <link rel="shortcut icon" type="image/x-icon" href="https://techshelter.albin.dev/favicon.png">
</head>

<h1>Introduction</h1>
<h3>What is an Azure Blob?</h3>
<p>
    Well to keep it short, an Azure blob is basically a literal big blob of data.
    It can be several files or just one file. You can then read the bytes of the blob to a new file or write additional bytes to the blob.

    The pros of a blob is mnany, but one of them is that it's quite simple in  it's design. It does not use any fancy standards like POSIX and thus the straightforward design makes it simple to extend, but also simple to use on several platforms.<br>
    A blob is most often used to store non-structured data such as multimedia, but honestly you can also use it to store variables or any other data. So it's quite flexible.<br><br>
    But since you may wish to use blobs for different reasons there are actually three types of blobs that are optimized for a specific use.
    <ul>
        <li><strong>Block blob:</strong> A block blob is a blob, but it's been thrown in a dice cutter and consist of several blocks forming your blob. This type of blob is optimized for file sharing</li>
        <li><strong>Page blob:</strong> A page blob is kind of different. It instead using pages that each consist of 512 bytes. This type of blob is optimized for storing your databases or partitions for your VM.</li>
        <li><strong>Append blob:</strong> An append blob works the same as a block blob, but as the name implies you primarily use it to append additional data. Therefore you are unable to update existing data nor deletion. An append blob can hold slightly more data than the previous types. It's optimized for uses when you continously wish to add data.</li>
    </ul>
    For this blog post I made a console application to manage Azure Blobs using a CLI(Command line interface) together with a classmate Robin Axelsson with pair programming. <a href="https://github.com/RobinAxelsson/ConsoleBlobApp" target="_blank" style="color: cornflowerblue !important;">The repository can be found here</a>
    <i>Disclaimer: The CLI extension with CommandLineParser was developed by Robin alone in a later stage since he wanted to do something fun out of it later. We initially used default command line args</i>
</p>
<h2>Making the app</h2><br>
<h5>Tools needed:</h5>
<p><ul>
    <li>Visual Studio Code</li>
    <li>Azure Storage Account</li>
    <li>Azure Storage Container</li>
    <li>GitHub Account</li>
</ul></p>
<h5>Dependencies needed:</h5>
<p><ul>
    <li>Azure Storage Blobs</li>
    <li>CommandLineParser</li>
    <li>NetEscapades Configuration YAML</li>
    <li>Microsoft Extensions Configuration User secrets</li>
    <li>Microsoft Extensions Configuration Environment variables</li>
    <li>Microsoft Extensions Configuration Commandline</li>
    <li>Microsoft Extensions Configuration(Core lib)</li>
</ul></p>
<h5>Retrieving the configuration</h5>
<img src="https://techshelter.albin.dev/img/posts/files_cloud/01.jpg"> <br>
<p>
    This code can be found in Program.cs and is called on each new instance of the application. By chaining our different configuration sources in this specific order it will let us use several sources in different priority orders.<br>
    For instance the end user can either store the secret connection string in dotnet secrets, or appsettings.yml. But if both exist we will always prioritize the secret.
    This way we can also distinguish testing from live when we develop the application as well which is handy.
</p>
<h5>Using the code</h5>
<p>
    By defining the class <strong>BlobContainerClient</strong> as <i>contaniner</i> null initially and then instantiating it on use we can split our Program.cs into different use cases depending on the core input of the arguments.
    <br>
    All the different input arguments are inherited from an interface we call IOption. Therefore we can firstly make the check if the input match the interface(In other words all valid arguments) and instantiate our container there.
    This saves us some lines of code since we don't have to copy paste the part where we set the container value on every case scenario.<br>
    This alsomakes it easier to expand the application.
    <img src="https://techshelter.albin.dev/img/posts/files_cloud/03.jpg">
    <br><br>
    Now that we have our container client, when we parse the "Add" command we check if the input file exist first by full path, but if that fails we attempt to combine the input URI with the working directory of the app incase you only specify filename and then lastly upload the file to our blob.
    <img src="https://techshelter.albin.dev/img/posts/files_cloud/02.jpg"><br><br>
    The rest of the application is fairly simple IO and string formatting using methods in the BlobClient such as <strong>DeleteBlob, DownloadTo, Upload, CreateIfNotExists.</strong>
    Using Azure Blobs was surprisingly simple only needing a few lines of code to work.
</p>
<h3>Storage types & data flow</h3>
<p>
    A blob can contain several <strong>files</strong> and a <strong>Container</strong> can contain several blobs. Lastly a <strong>Storage account</strong> can contain several containers.<br>
    Here is an example how you can separate blobs and containers.
    <img src="https://techshelter.albin.dev/img/posts/files_cloud/04.jpg">
    <br>
    <strong>Notice that some blobs say hot or cold? What does this mean?</strong><br>
    Well, there are three types of storage types using blobs.
    <ul>
        <li>Hot</li>
        <li>Cold</li>
        <li>Archive</li>
    </ul>
    The difference between these types are mainly the accessibility of your data.
    If you wish to frequently request and manipulate data you wan't to have hot storage. This gives you the fastest access, but also the highest price per gb. This is ideal for frequent access such as the latest version of your application downloadable on your website.<br>
    But if you have large amount of data that you don't plan to access often, but you still wish to keep the possibility to access it, you can use cold storage. This is ideal for maybe older versions of your application downloadable on your website.
    It gives you slower access to the files, but a much cheaper price per gb.
    <br><br>
    Lastly we have archive. And here you can store data that you never plan to access, but still want them stored. This is ideal for backups or maybe if you wish to keep an alpha/beta version of your application that is not downloadable. This is <strong>extremely</strong> cheap price per gb.<br><br>
    <h5>Application data flow</h5>
    The data flow for the application is quite simple. Below I've posted a diagram showing you the flow when adding a new file to an existing blob.<br>
    <img src="https://techshelter.albin.dev/img/posts/files_cloud/05.jpg">
</p>
<h3>Pricing</h3>
<p>If we put things into a scenario. Let us say we make a public blob insead for this CLI app that anyone can use.<br>
By spicing that scenario we imagine 1000 users uploading 100Mb of data each day. What would the intial cost be, and how would that cost increase over time? <br> <br>
Well this depends. If everything is hot storage we would land more expensive with a bigger server.
<br>
But what you could do is setting a margin, and structure your blobs. So data that get passed a certain date gets moved into cold storage. That way we can keep active data relevant and easy to retrieve while minimizing pricing for less relevant data.
How you would set this up obviously depends on your data consumption. You could set the margin to a number of visits over a certain time period if you were to have an imaging site for instance.
<br><br>
But to keep it simple and relevant I'll assume that we will <strong>only</strong> use hot storage because we don't care and want everything we have super accessible.
<br><br>
A thousand users uploading 100MB everyday will result in a total of <strong>97.6 GB/day</strong> We do not wish to purchase more too often so we expect to expand every year.
This would require us exactly 35624GBs or <strong>34.7 terabytes</strong> per year. Now also having an error margin of 20% so let's set our yearly server size to <strong>42TB</strong><br>
With a blob size limit of 200GB and our total size of 42TB would need us 216 blobs if we wish to maximize efficiency and just cramp every data into a free blob.<br>
With the 20% error margin we assume a writing of 120k per year and times that 10 for read(we assume people frequently look at photos) we would arrive at <strong>930$ per month</strong><br>
<img src="https://techshelter.albin.dev/img/posts/files_cloud/06.jpg"><br>
<img src="https://techshelter.albin.dev/img/posts/files_cloud/07.jpg"><br>
<br>
These costs would just double up every year assuming we in some imaginary world keep our service consumption completely static.(Well if that were the case we could actually remove the error margin and save a few bucks as well.)
</p>
<h3>Security</h3>
<p>
    Security is a big thing today. Internet is accessible to almost any human being on earth, and the cloud being accessible from anywhere makes this really important.
    You could basically hijack a file in two ways.
    When it's resting in the blob, or when it's in flight. Which means during transfers.<br>
    Therefore Microsoft needs to ensure both ways are encrypted.
</p>
<br><br>
<h5>Resting encryption</h5>
<p>
    The files on the hard drive are encrypted using AES256 Rijndael algorithm with padding, initialization vectors and an encryption key from the Azure key vault. This is combined with additional salt that is secret server-side.<br>
    The files are encrypted and decrypted everytime you make a request.
</p>
<h5>Flight encryption</h5>
<p>This is the toughest part. When the file you requested are being routed to your home, the file in transit is completely decrypted. That means someone could just eavesdrop or catch your packages mid-flight. To ensure nobody can listen or look at your transmision we need to encrypt the line.
    <br>
    This is achieved via an encrypted TLS(Transport Layer Security) protocol combined with Forward Secrecy protocol.<br>
    These protocols works a bit different but are very secure when combined.
    <h5>Encrypted TLS</h5>
    Encryped TLS works by making sure only the requesting computer and peek at the data. The transfer itself is encrypted both symetrically and assymetrically using a secret key only the server and client knows. This way only the client and server can see the content.
    <br>
    TLS evolved from SSL and is very common today.
    <br>
    <h5>Perfect Forward Secrecy</h5>
    This is a method for keeping all transmissions safe. Basically the protocol renew a new encryption key for every transmission instead of keeping a connection open.
    That means if you were to request 5 blocks in rapid succession each block would have a unique key instead of having a single encrypted transmission line.
</p>
<h5>Summary</h5>
The developers on Microsoft has been having security in their mind from the get-go when developing this service. The security of Azure is not compromised in any way and is probably even more secure than hosting it yourself locally.
<br>
<br>
<h6>Thank you for reading!</h6>
<p>/Albin</p>
<p><i>Sources:</i></p>
<a href="https://cloudacademy.com/blog/how-does-azure-encrypt-data/" target="_blank" style="color: cornflowerblue !important;">How Does Azure Encrypt Data?</a>

<br>

<a href="https://www.internetsociety.org/deploy360/tls/basics/" target="_blank" style="color: cornflowerblue !important;">TLS Basis</a>

<br>

<a href="https://www.youtube.com/watch?v=_Qlkvd4ZQuo" target="_blank" style="color: cornflowerblue !important;">AZ-900 Episode 11 | Azure Storage Services | Blob, Queue, Table, Files, Disk and Storage Tiers</a>

<br>

<a href="https://www.serverless360.com/blog/azure-blob-storage-vs-file-storage" target="_blank" style="color: cornflowerblue !important;">Azure Blob Storage vs File Storage</a>

<br>

<a href="https://www.c-sharpcorner.com/article/azure-storage-crud-operations-in-mvc-using-c-sharp-azure-table-storage-part-one/" target="_blank" style="color: cornflowerblue !important;">Azure Storage CRUD Operations In MVC Using C#</a>
